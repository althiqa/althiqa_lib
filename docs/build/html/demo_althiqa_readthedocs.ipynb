{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6945c1a",
   "metadata": {},
   "source": [
    "# Notebook example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582f710d",
   "metadata": {},
   "source": [
    "<h2>1) Experimentation: preprocessing and models training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0945eeaf",
   "metadata": {},
   "source": [
    "Let's use the mortgage dataset which is stemming from the Federal Financial Institutions Examination Council as the result of the Home Mortgage Disclosure Act: since 1975, lending institutions are required to report public loan data. </br>We will use a sample from 2016 to predict if an application was approved (1) or denied (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2077b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator\n",
    "import xgboost as xgb\n",
    "xgb.set_config(verbosity=0)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99df776",
   "metadata": {},
   "source": [
    "<h3> Data Preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f735ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_NAMES = collections.OrderedDict({\n",
    " 'as_of_year': np.int16,\n",
    " 'agency_code': 'category',\n",
    " 'loan_type': 'category',\n",
    " 'property_type': 'category',\n",
    " 'loan_purpose': 'category',\n",
    " 'occupancy': np.int8,\n",
    " 'loan_amt_thousands': np.float64,\n",
    " 'preapproval': 'category',\n",
    " 'county_code': np.float64,\n",
    " 'applicant_income_thousands': np.float64,\n",
    " 'purchaser_type': 'category',\n",
    " 'hoepa_status': 'category',\n",
    " 'lien_status': 'category',\n",
    " 'population': np.float64,\n",
    " 'ffiec_median_fam_income': np.float64,\n",
    " 'tract_to_msa_income_pct': np.float64,\n",
    " 'num_owner_occupied_units': np.float64,\n",
    " 'num_1_to_4_family_units': np.float64,\n",
    " 'approved': np.int8\n",
    "})\n",
    "\n",
    "def preprocessing(data):\n",
    "    data = pd.read_csv(data, index_col=False, dtype=COLUMN_NAMES)\n",
    "    data = data.dropna()\n",
    "    data = shuffle(data, random_state=2)\n",
    "    labels = data['approved']\n",
    "    data_dropped_approved = data.drop(columns=['approved', 'purchaser_type'])\n",
    "    dummy_columns = list(data_dropped_approved.dtypes[data.dtypes == 'category'].index)\n",
    "    data_dropped_approved = pd.get_dummies(data_dropped_approved, columns=dummy_columns)\n",
    "    x,y = data_dropped_approved,labels.values\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y, random_state=2)\n",
    "    x_train = x_train.drop(columns='Unnamed: 0')\n",
    "    missing = [elt for elt in x_test.columns if elt not in x_train.columns]\n",
    "    for col in missing:\n",
    "        x_test = x_test.drop(columns= col)\n",
    "    assert x_test.columns.any() == x_train.columns.any()\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b7ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocessing(\"mortgage_extra_small.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac1ceda",
   "metadata": {},
   "source": [
    "Now let's prepare a pytorch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d1918",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "train_data = TrainData(torch.FloatTensor(X_train.to_numpy()), \n",
    "                       torch.FloatTensor(y_train))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, \n",
    "                          batch_size=64, \n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180cd9b9",
   "metadata": {},
   "source": [
    "<h3> Models Training</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082ad4d8",
   "metadata": {},
   "source": [
    "Let's train 4 competing models models: an xgboost, a RandomForst, a logistic regression and a fully connected pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e626256",
   "metadata": {},
   "outputs": [],
   "source": [
    "xboost_depth_3 = xgb.XGBClassifier(\n",
    "                objective='binary:logistic',\n",
    "                max_depth = 3\n",
    "            ).fit(X_train, y_train, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb46c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "                n_estimators=50, \n",
    "                max_depth=7, \n",
    "                random_state=0\n",
    "            ).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e117d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr =  LogisticRegression(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8613642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        # Number of input features is 34.\n",
    "        self.layer_1 = nn.Linear(34, 64) \n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b77b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp = MLP()\n",
    "LEARNING_RATE = 0.001\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model_mlp.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90295e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "for e in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model_mlp(X_batch)\n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9231c4",
   "metadata": {},
   "source": [
    "<h2>2) Use althiqa's API to create your report</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9995099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import althiqa_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da1cbd4",
   "metadata": {},
   "source": [
    "<h3>Login</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ccae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://ec2-15-188-65-181.eu-west-3.compute.amazonaws.com:8000'\n",
    "pwd='password_demo0!'\n",
    "email = 'victor.storchan@althiqa.io'\n",
    "\n",
    "sess = althiqa_lib.Session(url, email, pwd )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef06c253",
   "metadata": {},
   "source": [
    "<h3>Create your project</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1bc9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = sess.create_project(\"Credit Scoring Mortgage21\",  \n",
    "                               X_train, \n",
    "                               y_train, \n",
    "                               X_test, \n",
    "                               y_test, \n",
    "                               project_type=\"classif\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732edef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "project2 = sess.get_project('Credit Scoring Mortgage12')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f3ae8",
   "metadata": {},
   "source": [
    "<h3>Push your models to evaluate, compare and rank them </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d908a0be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project.push_model('xgboost3', xboost, threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc1175",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.push_model('xboost_depth_3', xboost_depth_3, threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214bc8d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project.push_model('random forest', rf, threshold = 0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ca997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project.push_model('logistic regression', lr, threshold = 0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a3e7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrapperPytorchClassif(BaseEstimator):\n",
    "    def __init__(self, model =None, X=None, y=None):\n",
    "        self.model = model\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if type(X) != torch.Tensor:\n",
    "            X = torch.FloatTensor(X.to_numpy())\n",
    "        y_test_pred = self.model(X)\n",
    "        y_pred_tag = torch.sigmoid(y_test_pred)\n",
    "        y = pd.DataFrame(y_pred_tag.detach().numpy())\n",
    "        y = y.to_numpy()\n",
    "        y = np.asarray([[1-float(elt), float(elt)] for elt in y])\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc076b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wrapped_MLP = WrapperPytorchClassif(model = model_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aded4ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project.push_model('MLP', Wrapped_MLP, threshold = 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f66a628",
   "metadata": {},
   "source": [
    "<h3>Push any custom metrics that are relevant to the project</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e06988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's define a custom ROI metric\n",
    "def ROI_custom(y_pred, y_test, x_test):\n",
    "    interest_rate = 0.05\n",
    "    num_years = 10\n",
    "    cumul_roi = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == 0 and y_test[i] == 0:\n",
    "            pass\n",
    "        if y_pred[i] == 1 and y_test[i] == 0:\n",
    "            cumul_roi -= x_test.iloc[i][\"loan_amt_thousands\"]\n",
    "        if y_pred[i] == 1 and y_test[i] == 1:\n",
    "            cumul_roi+= x_test.iloc[i][\"loan_amt_thousands\"]*((1+interest_rate)**num_years-1)/interest_rate\n",
    "        if y_pred[i] == 0 and y_test[i] == 1:\n",
    "            cumul_roi-= x_test.iloc[i][\"loan_amt_thousands\"]*((1+interest_rate)**num_years-1)/interest_rate\n",
    "    return cumul_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487a2c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.create_metric('ROI', ROI_custom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
